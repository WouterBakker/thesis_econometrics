{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type I for regular and weighted (NA zeroed out) coefficient estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First try to optimize for regular estimation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_FE_regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class_FE_regression.panel_estimation at 0x11fcee790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 30\n",
    "T = 15\n",
    "beta = [0, 0]\n",
    "K = len(beta)\n",
    "min_var, max_var = 0, 2\n",
    "shrink_factor = 0 # set > 0 to generate cross-sectional correlation of size max_var/shrink_factor\n",
    "range_theta = [0,10]\n",
    "reps = int(1e4)                              \n",
    "\n",
    "sim1 = panel_simulation(N, T, beta, reps, min_var, max_var, range_theta, shrink_factor)\n",
    "sim1.simulate_Y()\n",
    "\n",
    "est_unweighted = panel_estimation(sim1.X_observed, sim1.Y, N, T, method = 'FE_OLS')\n",
    "est_unweighted.estimate_coefs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0578, 0.0576])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_unweighted.calc_t_values()\n",
    "est_unweighted.rejection_rate()\n",
    "est_unweighted.proportion_H0_rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted FE OLS\n",
    "- Now, do the adjusted version for the weighted FE OLS.\n",
    "    - Need df adjustment to exclude the missing observations in df calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class_FE_regression.panel_estimation at 0x11fceeb90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate removing missing datapoints\n",
    "# Randomly select missing_prob amount of indices to set to NA for X\n",
    "missing_prob = 0.1\n",
    "missing_indices_X = np.random.rand(*sim1.X.shape) < missing_prob  # Define a probability for missing data\n",
    "\n",
    "sim1.X_observed[missing_indices_X] = np.nan\n",
    "\n",
    "est_weighted = panel_estimation(sim1.X_observed, sim1.Y, N, T, method = 'weighted_FE_OLS')\n",
    "est_weighted.estimate_coefs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0578, 0.0576])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_weighted.calc_t_values()\n",
    "est_weighted.rejection_rate()\n",
    "est_unweighted.proportion_H0_rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare type I error (rejection rate) in weighted vs unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Type I error: [0.0604 0.0588]\n",
      "Weighted Type I error: [0.0565 0.0554]\n"
     ]
    }
   ],
   "source": [
    "# Compare \n",
    "print(f\"Unweighted Type I error: {est_unweighted.proportion_H0_rejected}\\nWeighted Type I error: {est_weighted.proportion_H0_rejected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "- Type I error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_I_error_revamped():    \n",
    "\n",
    "    # Tensor implementation of Type I errors\n",
    "    ## First calculates the t-values for all the coefficients\n",
    "    ## Then calculates whether the coefficient rejects H0 of beta=0\n",
    "    ## Since true beta equals 0, it should not reject H0, hence computing the type I errors\n",
    "    ### Based on Pesaran p.642,643\n",
    "\n",
    "    # Compute residuals\n",
    "    H0 = np.zeros(K)\n",
    "    # resids_all = est1.M_dot_Y - np.einsum('hntr, r -> hnt', est1.M_dot_X, np.zeros(2))\n",
    "    resids_all = est1.M_dot_Y - np.einsum('hntr, r -> hnt', est1.M_dot_X, H0)\n",
    "\n",
    "    # Compute variance for each N\n",
    "    variances_all = np.sum(resids_all ** 2, axis = 2) / T\n",
    "\n",
    "    # Construct Gamma matrices, is RepsxNxTxT\n",
    "    ## Each TxT matrix has the corresponding variance on the diagonal\n",
    "    identity_matrices = np.tile(np.eye(T), (reps, N, 1, 1))\n",
    "    Gamma = identity_matrices * variances_all[:, :, np.newaxis, np.newaxis]\n",
    "\n",
    "    V_FENT = np.einsum('anti,antj,antk->aik', est1.M_dot_X, Gamma, est1.M_dot_X)\n",
    "    Omega = np.einsum('aij,ajk,akl->ail', est1.Q_inv, V_FENT, est1.Q_inv)\n",
    "\n",
    "    # Compute the square root of the diagonal elements of Omega\n",
    "    diagonal_sqrt_Omega = np.sqrt(np.diagonal(Omega, axis1=1, axis2=2))\n",
    "\n",
    "    # Divide the coefficients by the square root of the diagonal elements\n",
    "    t_vals = est1.coefficients / diagonal_sqrt_Omega\n",
    "\n",
    "    # Calculate degrees of freedom and critical value\n",
    "    df = N * T - 2 - N  # degrees of freedom\n",
    "    critical_value = scipy.stats.t.ppf(1 - 0.05 / 2, df)\n",
    "\n",
    "    # Calculate absolute t-values\n",
    "    abs_t_vals = np.abs(t_vals)\n",
    "\n",
    "    # Count the number of rejections for beta1 and beta2\n",
    "    nr_of_rejections_beta = []\n",
    "\n",
    "    for k in range(K):\n",
    "        nr_of_rejections_beta.append(np.sum(abs_t_vals[:, k] > critical_value))\n",
    "\n",
    "    proportion_H0_rejected = np.array(nr_of_rejections_beta) / reps\n",
    "\n",
    "    print(proportion_H0_rejected)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_I_error():    \n",
    "    t_vals = []\n",
    "    M = np.eye(T) - (1/T) * np.ones((T, T))\n",
    "\n",
    "\n",
    "    for rep in range(reps):\n",
    "        X = M @ sim1.X_observed[rep]\n",
    "        y = sim1.Y[rep] @ M\n",
    "        beta = est1.coefficients[rep]\n",
    "        \n",
    "        resids = y - ((X @ beta))\n",
    "        \n",
    "        variances = np.sum(resids ** 2, axis = 1) / (T)\n",
    "        \n",
    "        V_FENT = np.zeros((2,2))\n",
    "        Q_FENT = np.zeros((2,2))\n",
    "\n",
    "        for i in range(N):\n",
    "            Gamma_i = np.eye(T) * variances[i]\n",
    "            V_FENT += X[i].T @ M @ Gamma_i @ M @ X[i]\n",
    "            Q_FENT += X[i].T @ M @ X[i]\n",
    "            \n",
    "        Q_inv = est1.Q_inv[rep]\n",
    "        Omega = Q_inv @ V_FENT @ Q_inv\n",
    "        t_vals.append(est1.coefficients[rep] / np.sqrt(np.diag(Omega)))\n",
    "\n",
    "\n",
    "    df = N*T - 2 - N# degrees of freedom\n",
    "    critical_value = scipy.stats.t.ppf(1 - 0.05 / 2, df)\n",
    "\n",
    "    rejections_beta1 = 0\n",
    "    rejections_beta2 = 0\n",
    "\n",
    "    for t_val in t_vals:\n",
    "        if abs(t_val[0]) > critical_value:\n",
    "            rejections_beta1 += 1\n",
    "        if abs(t_val[1]) > critical_value:\n",
    "            rejections_beta2 += 1\n",
    "\n",
    "    print(rejections_beta1/reps, rejections_beta2/reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "T = 15\n",
    "beta = [0, 0]\n",
    "K = len(beta)\n",
    "min_var, max_var = 0, 2\n",
    "shrink_factor = 0 # set > 0 to generate cross-sectional correlation of size max_var/shrink_factor\n",
    "range_theta = [0,10]\n",
    "reps = int(1e4)                              \n",
    "\n",
    "sim1 = panel_simulation(N, T, beta, reps, min_var, max_var, range_theta, shrink_factor)\n",
    "sim1.simulate_Y()\n",
    "\n",
    "est_unweighted = panel_estimation(sim1.X_observed, sim1.Y, N, T, method = 'FE_OLS')\n",
    "est_unweighted.estimate_coefs()\n",
    "\n",
    "betaa = np.array(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Speed comparison of old (slow) implementation vs optimized (with tensor contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_I_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_I_error_revamped()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
